{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NE China to expand protection area for Siberian tigers\n",
      "Shaanxi innovation area looking to expand\n",
      "Toxic case echoes US Love Canal disaster\n",
      "China to help more rural migrants settle in cities\n",
      "Health department dismisses parents' cancer fears\n",
      "City takes bite out of delivery issues\n",
      "Govt officials beat restaurant owner to death\n",
      "Meeting focuses on land use, protection\n",
      "China to enjoy the second population dividend\n",
      "Discharged iron turns polluted river red-brown\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "\n",
    "\n",
    "url_list = ['http://www.chinadaily.com.cn/china/2016-04/20/content_24701635.htm',\n",
    "            'http://www.chinadaily.com.cn/china/2016-04/20/content_24700746.htm',\n",
    "            'http://www.chinadaily.com.cn/china/2016-04/20/content_24681482.htm',\n",
    "            'http://www.chinadaily.com.cn/china/2016-04/19/content_24675530.htm',\n",
    "            'http://www.chinadaily.com.cn/china/2016-04/19/content_24675455.htm',\n",
    "            'http://www.chinadaily.com.cn/china/2016-04/19/content_24674074.htm',\n",
    "            'http://www.chinadaily.com.cn/china/2016-04/19/content_24655536.htm',\n",
    "            'http://www.chinadaily.com.cn/china/2016-04/18/content_24643685.htm',\n",
    "            'http://www.chinadaily.com.cn/china/2016-04/18/content_24636917.htm',\n",
    "            'http://www.chinadaily.com.cn/china/2016-04/15/content_24562198.htm'\n",
    "            ]\n",
    "\n",
    "articles_title = []\n",
    "articles_content = []\n",
    "# 解析\n",
    "for pos,url in enumerate(url_list):\n",
    "    r = requests.get(url)\n",
    "    soup1 = bs4.BeautifulSoup(r.text,'lxml')\n",
    "    soup2 = bs4.BeautifulSoup(str(soup1.find_all(id=\"Title_e\")),'lxml')\n",
    "    print(soup2.h1.string)\n",
    "    articles_title.append(soup2.h1.string)\n",
    "    mystr = \"\"\n",
    "    soup3 = bs4.BeautifulSoup(str(soup1.find_all(id=\"Content\")),'lxml')\n",
    "    for x in soup3.find_all(\"p\"):\n",
    "        mystr = mystr + x.string\n",
    "#         print(mystr)\n",
    "#    初始化\n",
    "    str_p = \"\"\n",
    "    contents = []\n",
    "# 去掉标点,分词\n",
    "    for pos,x in enumerate(mystr):\n",
    "        if x == '.' or x == ',':\n",
    "            if pos < (len(mystr) - 1) and mystr[pos+1] >= '0' and mystr[pos+1] <= '9':\n",
    "                str_p = str_p + x\n",
    "            elif str_p == \"\":\n",
    "                continue\n",
    "            else:\n",
    "                contents.append(str_p)\n",
    "                str_p = \"\"\n",
    "        elif x == '(' or x == ')' or x == ' ' or x == '\"' or x == '[' or x == ']' or x == '-':\n",
    "            if str_p == \"\":\n",
    "                continue\n",
    "            else:\n",
    "                contents.append(str_p)\n",
    "                str_p = \"\"\n",
    "        else:\n",
    "            str_p = str_p + x\n",
    "    articles_content.append(contents)\n",
    "\n",
    "Dict_idf = {}\n",
    "DictList = []\n",
    "\n",
    "for content in articles_content:\n",
    "    Dict_tf = {}\n",
    "    for x in content:\n",
    "#         if not Dict_tf.has_key(x):\n",
    "        if x not in Dict_tf.keys():\n",
    "            Dict_tf[x] = 1.0\n",
    "            if x not in Dict_idf.keys():\n",
    "#             if not Dict_idf.has_key(x):\n",
    "                Dict_idf[x] = 1.0\n",
    "            else:\n",
    "                Dict_idf[x] += 1.0\n",
    "        else:\n",
    "            Dict_tf[x] += 1.0\n",
    "\n",
    "    for k, v in Dict_tf.items():\n",
    "        Dict_tf[k] = v / len(content)\n",
    "\n",
    "    DictList.append(Dict_tf)\n",
    "\n",
    "for k, v in Dict_idf.items():\n",
    "    Dict_idf[k] = math.log(float(len(url_list)) / v)\n",
    "\n",
    "for pos,x in enumerate(DictList):\n",
    "    for k,v in x.items():\n",
    "        DictList[pos][k] = v*Dict_idf[k]\n",
    "    DictList[pos] = sorted(x.items(), key=lambda d: d[1], reverse=True)\n",
    "\n",
    "\n",
    "data = []\n",
    "for pos in range(10):\n",
    "    data2=[]\n",
    "    data2.append(\"article_titile:\")\n",
    "    data2.append(articles_title[pos])\n",
    "    data2.append([{\"word\": k,\"value\":round(v,4)} for k,v in DictList[pos][:10]])\n",
    "    data.append(data2)\n",
    "\n",
    "# Writing JSON data\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'fromkeys',\n",
       " 'get',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'pop',\n",
       " 'popitem',\n",
       " 'setdefault',\n",
       " 'update',\n",
       " 'values']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
